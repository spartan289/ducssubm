{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:50:54.423176Z",
     "start_time": "2024-10-18T13:50:53.780100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabccdcc8381aa3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:50:55.108467Z",
     "start_time": "2024-10-18T13:50:55.092828Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56498a74c89a6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:50:56.739622Z",
     "start_time": "2024-10-18T13:50:55.361463Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# \n",
    "# import pandas as pd\n",
    "# import rouge\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "# from rouge import Rouge\n",
    "# train = pd.read_csv('public_dat/train.csv')\n",
    "# test = pd.read_csv('testfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95b5d07af3d15f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:51:55.484145Z",
     "start_time": "2024-10-18T13:50:59.537782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Sagar\n",
      "[nltk_data]     Rathore\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "100%|██████████| 561838/561838 [00:40<00:00, 13774.20it/s]\n",
      "100%|██████████| 184664/184664 [00:13<00:00, 13250.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import rouge\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "train = pd.read_csv('public_dat/train.csv')\n",
    "test = pd.read_csv('testfinal.csv')\n",
    "import nltk\n",
    "#apply stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "ps = PorterStemmer()\n",
    "def stem(text):\n",
    "    words = word_tokenize(text)\n",
    "    return ' '.join([ps.stem(w) for w in words])\n",
    "def preprocess(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    #remove number \n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #remove 1 and 2 length words\n",
    "    text = ' '.join([w for w in text.split() if len(w) > 2])\n",
    "    text = stem(text)\n",
    "\n",
    "    if len(text)==0:\n",
    "        \n",
    "        return '[NUM]'\n",
    "    \n",
    "    return text\n",
    "train['clean_description'] = train['description'].progress_apply(preprocess)\n",
    "test['clean_description'] = test['description'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099a203dcf488c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:38:40.263010Z",
     "start_time": "2024-10-18T14:38:40.248548Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_simon_similarity(pairs1, pairs2):\n",
    "    \"\"\"\n",
    "    Perform trigram comparison between two small input strings\n",
    "    and return a percentage match in decimal form.\n",
    "    Optimized for small inputs by reducing redundant loops.\n",
    "    \"\"\"\n",
    "    # Convert pairs2 to a set for O(1) lookup times\n",
    "    pairs2_set = set(pairs2)\n",
    "\n",
    "    hit_count = sum(1 for x in pairs1 if x in pairs2_set)\n",
    "\n",
    "    union = len(pairs1) + len(pairs2)\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    return 0.6 * hit_count / (min(len(pairs1), len(pairs2)) + 1) + 0.4 * hit_count / (len(pairs1) + 1)\n",
    "        # Convert pairs2 to a set for O(1) lookup times\n",
    "\n",
    "def get_trigrams(string):\n",
    "    \"\"\"\n",
    "    Take a string and return a list of bigrams.\n",
    "    \"\"\"\n",
    "    if string is None:\n",
    "        return \"\"\n",
    "\n",
    "    s = string.lower()\n",
    "    return [s[i : i + 3] for i in list(range(len(s) - 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f7b27bee19a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:13:49.200893Z",
     "start_time": "2024-10-18T14:13:45.050719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561838/561838 [00:03<00:00, 163841.76it/s]\n",
      "100%|██████████| 184664/184664 [00:00<00:00, 329712.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train['bigram'] = train['clean_description'].progress_apply(get_trigrams)\n",
    "test['bigram'] = test['clean_description'].progress_apply(get_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9932c82e8afce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:38:42.869211Z",
     "start_time": "2024-10-18T14:38:42.852196Z"
    }
   },
   "outputs": [],
   "source": [
    "def match_simon(test_row, train):\n",
    "    scores = train['bigram'].apply(lambda x: custom_simon_similarity(test_row, x))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2feab72ccb32df9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:38:43.110621Z",
     "start_time": "2024-10-18T14:38:43.097900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0578f64b581981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:39:20.425991Z",
     "start_time": "2024-10-18T14:38:43.843986Z"
    }
   },
   "outputs": [],
   "source": [
    "#find for each row in test\n",
    "#apply tqdm for loop\n",
    "\n",
    "# matching simon similarity for each row in test with all test rows and storing top 30 most matching instances\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    score = match_simon(test['bigram'][i], train)\n",
    "    top30 = train.iloc[score.sort_values(ascending=False).head(30).index]\n",
    "    test.loc[i, 'supergroup'] = top30['supergroup'].value_counts().idxmax()\n",
    "    test.loc[i, 'group'] = top30['group'].value_counts().idxmax()\n",
    "    test.loc[i, 'module'] = top30['module'].value_counts().idxmax()\n",
    "    # save the top 30 matching instances\n",
    "    \n",
    "test.to_csv('submissiontest.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b523f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "#for every row in train\n",
    "submission_test = pd.read_csv('submissiontest.csv')\n",
    "# t5 predictions brand\n",
    "testt5 = pd.read_csv(\"testpredictt51st.csv\")\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "for index, row in tqdm(submission_test.iterrows(), total=submission_test.shape[0]):\n",
    "    indexes = row['si_index']\n",
    "    #select these indexes from the tr (training dataset) dataframe\n",
    "    selected = train.iloc[indexes]\n",
    "    #selected supergroup with max count in top 30\n",
    "    supergroup = row['supergroup']\n",
    "    selected = selected[selected['supergroup'] == supergroup]\n",
    "    score = match_simon(submission_test['bigram'][index], selected)\n",
    "    selected = selected[score == score.max()]\n",
    "    # select group with max simon similarity in that selected supergroup from top30\n",
    "    # select module with max simon similarity in that selected group from top30\n",
    "    group = selected['group'].value_counts().idxmax()\n",
    "    module = selected['module'].value_counts().idxmax()\n",
    "    sub.at[index, 'indoml_id'] = row['indoml_id']\n",
    "    sub.at[index, 'supergroup'] = supergroup\n",
    "    sub.at[index, 'group'] = group\n",
    "    sub.at[index, 'module'] = module\n",
    "\n",
    "sub['brand'] = testt5['brand']\n",
    "\n",
    "import json\n",
    "categories = ['supergroup','group','module','brand']\n",
    "\n",
    "with open('submitpredictions.predict', 'w') as file:\n",
    "    for index, row in sub.iterrows():\n",
    "        result = {}\n",
    "        result['indoml_id'] = row['indoml_id']\n",
    "        for category in categories:\n",
    "            result[category] = row[category]\n",
    "        file.write(json.dumps(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c166f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
